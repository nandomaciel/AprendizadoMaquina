{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dia 2 - Métodos Supervisionados\n",
    "Tópicos que serão abordados: \n",
    "- Métodos supervisionados:\n",
    "    - Regressão Linear\n",
    "    - KNN\n",
    "    - Árvore de decisão\n",
    "    - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Bibliotecas usadas:<br>\n",
    "Scikit-learn http://scikit-learn.org/stable/index.html<br>\n",
    "Matplotlib https://matplotlib.org/api/pyplot_api.html<br>\n",
    "Pandas http://pandas.pydata.org/pandas-docs/stable/<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passo a passo de como tratar um problema\n",
    "1. Formulação do problema\n",
    "2. Base de dados\n",
    "3. Tratamento dos dados (quando necessário)\n",
    "4. Treinamento dos algoritmos\n",
    "5. Predição para novos elementos \n",
    "6. Análise dos resultados (opcional, porém recomendado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Linear\n",
    "\n",
    "Uma forma de calcular regressão linear é utilizando Mínimos Quadrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando bibliotecas necessárias\n",
    "# Dúvidas? veja links para documentações acima\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse primeiro momentos iremos trabalhar com uma base de dados chamada diabetes, nosso problema é conseguir estimar como é a taxa de glicose de uma pessoa (se é diabética) considerando uma série de atributos associados a essa pessoa.\n",
    "\n",
    "Com isso, nosso segundo passo é conhecer a base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando a base de dados \"diabetes\"\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Base de dados contém um array bidimensinal do numpy de dimensões 442,10 (data)\n",
    "# (442 arrays com 10 elementos cada)\n",
    "X = diabetes.data\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada linha em data é uma sample (amostra): nesse caso, um paciente; com 10 features (atributos) cada, informações coletadas sobre eles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# E um array simples com 442 elementos (target)\n",
    "y = diabetes.target\n",
    "print(type(y))\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada número em target é um valor associado à uma das linhas de data, algo que vamos querer prever dado uma nova amostra fora do nosso conjunto de dados inicial.<br>\n",
    "Nesse caso podemos dizer que temos um dataset que nos dá o nível de glicose de um paciente (o target) junto a outras informações dele (atributos).<br>\n",
    "\n",
    "Vamos agora separar esses dados de forma que parte será usada para treinar esse modelo, e parte para testá-lo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separa apenas parte dos atributos para serem utilizados\n",
    "atr = 2\n",
    "X = diabetes.data[:,np.newaxis, atr]\n",
    "\n",
    "# Separando a base de dados entre treinamento e teste\n",
    "# test_size determina a porcentagem de dados que irá ser guardada para testes\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=6)\n",
    "\n",
    "# Criando um objeto de regressão linear\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Treinamento usando X e y\n",
    "linreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente vamos executar o algoritmo para novos elementos (que ficaram separados na parte de teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Obtendo predição do primeiro valor no array de testes:\n",
    "pred = linreg.predict(X_test[0])\n",
    "\n",
    "print(\"Para o primeiro valor no array de testes:\")\n",
    "print(\"-> Valor estimado %.2f.\" % pred)\n",
    "print(\"-> Valor real é %.2f.\" % y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguir fazemos uma análise do desempenho do algoritmo. Ao ligarmos cada ponto (o valor estimado) a reta diagonal, temos a distância que mede o erro do algoritmo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Imprimindo os coeficientes de cada feature estimados para a regressão da diabetes\n",
    "print('Coeficientes: ', linreg.coef_)\n",
    "# e a constante associada\n",
    "print('Constante: ', linreg.intercept_)\n",
    "\n",
    "# Obtendo previsões para todo o conjunto de testes\n",
    "y_pred = linreg.predict(X_test)\n",
    "\n",
    "# Cálculo do Erro quadrático médio\n",
    "print(\"Erro quadrático médio: %.2f\"\n",
    "      % np.mean((y_pred - y_test) ** 2))\n",
    "# Cálculo da variância\n",
    "print('Variância: %.2f' % linreg.score(X_test, y_test))\n",
    "\n",
    "# Gráficos\n",
    "plt.scatter(X_test, y_test,  color='black')\n",
    "plt.plot(X_test, y_pred, color='blue', linewidth=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos fazer mais um exemplo usando agora Pandas e um novo banco de dados considerando todos os atributos dessa vez: preços de casas em Boston. Nosso problema é estimar o valor das casas (descrição completa da base será mostrada a seguir). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "boston = datasets.load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quantidade de linhas por colunas:\", boston.data.shape)\n",
    "print(\"Nomes das colunas:\", boston.keys())\n",
    "print(\"Atributos:\", boston.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos passar a base de dados para um objeto Panda\n",
    "boston_pd = pd.DataFrame(boston.data)\n",
    "boston_pd.columns = boston.feature_names\n",
    "boston_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acrescentando uma coluna com os valores \n",
    "boston_pd[\"PRICE\"] = boston.target\n",
    "boston_pd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 1 (Regressão Linear)\n",
    "Divida a base de dados em uma parte para treino e outra para testes e faça as estimativas. Também desenhe um gráfico com eixo X valor estimado e eixo Y valor real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbors (KNN)\n",
    "\n",
    "Vamos ao segundo algoritmo de aprendizado não supervisionado, chamado KNN. Nesse primeiro momento vamos apresentar o KNN como um classificador. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dúvidas sobre documentação? Disponível em \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import neighbors, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nosso objetivo nesse momento é saber classificar plantas Íris. A base de dados possui 3 classes, 50 amostras de cada uma. Nesse primeiro momento vamos utilizar apenas um atributo para fazer as etimativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de dados (http://archive.ics.uci.edu/ml/datasets/Iris)\n",
    "iris = datasets.load_iris()\n",
    "print(iris.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(iris.data)\n",
    "X = iris.data[:, :2] # selecionando apenas o que nos interessa\n",
    "print(X)\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Definição de alguns parâmetros\n",
    "# Quantidade de vizinhos que será considerada\n",
    "n_neighbors = 15\n",
    "h = 0.1 \n",
    "# Cores que serão utilizadas nos gráficos\n",
    "cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA', '#AAAAFF'])\n",
    "cmap_bold = ListedColormap(['#FF0000', '#00FF00', '#0000FF'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processo de treinamento e testes é feito a seguir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# O algoritmo será executado duas vezes para os casos em que o \n",
    "# o parâmetro weights é uniform e depois distance (muda a função utilizada para fazer predições),\n",
    "# também pode ser informada uma função definida pelo usuário\n",
    "# Esse parâmetro é a função utilizada para predição de novos valores, \n",
    "# o peso que vamos dar aos vizinhos\n",
    "for weights in ['uniform', 'distance']:\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    # Gera os valores de x_min a x_max e y_min a y_max \n",
    "    # e depois gera todos os pontos possíveis entre esses dois valores\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "    points = np.c_[xx.ravel(), yy.ravel()]\n",
    "    \n",
    "    Z = clf.predict(points)\n",
    "\n",
    "    # Formata Z para ficar com a mesma quantidade de linhas e colunas de xx e yy\n",
    "    # Pontos usados para plotar a parte mais clara do gráfico\n",
    "    # Dessa forma, temos xx[i], yy[i], Z[i] como sendo Z[i] a classe para o ponto xx[i],yy[i]\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure()\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light) # Usado para pintar um grid \n",
    "\n",
    "    # Plota os pontos usados como treino\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold, marker=\"^\")\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(\"Classificação com 3 classes (k = %i, weights = '%s')\"\n",
    "              % (n_neighbors, weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Esclarecimentos a respeito do que acontece dentro do loop (com um exemplo mais simples)\n",
    "#xx, yy = np.meshgrid(np.arange(0, 1, 0.2), np.arange(2, 3, 0.2))\n",
    "#print(xx)\n",
    "#print(yy)\n",
    "#print(xx.ravel())\n",
    "#np.c_[xx.ravel(), yy.ravel()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos apresentar o KNN como um estimador. Portanto, nosso problema muda para aprender a estimar os valores para novos objetos além dos que foram usados para treino. \n",
    "\n",
    "Essa estimativa é feita pegando os K elementos mais próximos do ponto que pretendemos estimar e calculando a média deles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dúvidas? Mais informações disponíveis em:\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html\n",
    "# Importando pacotes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "\n",
    "##############################################################################\n",
    "# Nossa base de dados gerada aleatoriamente\n",
    "##############################################################################\n",
    "# Gerando uma base de dados aleatória\n",
    "np.random.seed(0)\n",
    "X = np.sort(5 * np.random.rand(40, 1), axis = 0)\n",
    "T = np.linspace(0, 5, 500)[:, np.newaxis]\n",
    "y = np.sin(X).ravel()\n",
    "\n",
    "# Adicionando ruídos\n",
    "y[::5] += 1 * (0.5 - np.random.rand(8))\n",
    "\n",
    "##############################################################################\n",
    "# Parâmetros\n",
    "##############################################################################\n",
    "n_neighbors = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num = None, figsize = (6, 7), dpi = 80)\n",
    "for i, weights in enumerate(['uniform', 'distance']):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors, weights = weights)\n",
    "    ##############################################################################\n",
    "    # Treinamento\n",
    "    ##############################################################################\n",
    "    pred = knn.fit(X, y)\n",
    "    \n",
    "    ##############################################################################\n",
    "    # Testes\n",
    "    ##############################################################################\n",
    "    y_ = pred.predict(T)\n",
    "    \n",
    "    ##############################################################################\n",
    "    # Exibição dos resultados em gráfico\n",
    "    ##############################################################################\n",
    "    plt.subplot(2, 1, i + 1)\n",
    "    plt.scatter(X, y, c = 'k', label = 'data')\n",
    "    plt.plot(T, y_, c = 'g', label = 'prediction')\n",
    "    plt.axis('tight')\n",
    "    plt.legend()\n",
    "    plt.title(\"Regressão usando KNN (k = %i, weights = '%s')\" % (n_neighbors,\n",
    "                                                                weights))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 2 (KNN)\n",
    "\n",
    "Vamos fazer uma comparação entre a regressão linear e o KNN (como estimadores)?\n",
    "\n",
    "A base de dados utilizada a seguir é composta por uma lista de imagens. O que vamos fazer é ensinar os algoritmos usando a primeira metade da imagens (isto é, a primeira metade dos pixels) e depois usar a segunda metade para como saída esperada. Parte da base deve ser usada como treino e parte como teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "from sklearn.utils.validation import check_random_state     # gerador de valores aleatórios do sklearn\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa parte carregar a base de dados e separar treino de teste e selecionar um subgrupo aleatório de pessoas dos testes que serão usadas para imprimir o resultados (escolha uma mostra pequena dos testes para imprimir, user n_faces = 4 ou n_faces = 5, por exemplo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_faces = fetch_olivetti_faces()\n",
    "print(data_faces.DESCR)\n",
    "targets = data_faces.target\n",
    "print(data_faces.images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_faces = data_faces.images.reshape((len(data_faces.images), -1))\n",
    "print(data_faces.shape)\n",
    "train = data_faces[targets < 30]\n",
    "test = data_faces[targets >= 30] \n",
    "\n",
    "# Selecionando um subgrupo aleatório de pessoas (para imprimir posteriormente)\n",
    "n_faces = 5\n",
    "seed = 3\n",
    "rng = check_random_state(seed)\n",
    "face_ids = rng.randint(test.shape[0], size=(n_faces, ))      # gera n_faces ids para faces \n",
    "test = test[face_ids, :]\n",
    "\n",
    "# Parte que o aluno deve fazer\n",
    "n_pixels = data_faces.shape[1]\n",
    "# Parte superior das faces\n",
    "X_train = train[:, :(n_pixels + 1) // 2]      # Dada a quantidade total de pixels, pega os N primeiros\n",
    "X_test = test[:, :(n_pixels + 1) // 2]\n",
    "\n",
    "# Parte inferior das faces\n",
    "y_train = train[:, n_pixels // 2:]      # Dada a quantidade total de pixels, pega os N últimos\n",
    "y_test = test[:, n_pixels // 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nessa parte você deve treinar os algoritmos e ter como resultado um dicionário y_test_predict que tem o nome do algoritmo como chave e um array com os valores estimados como valor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solução"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimadores\n",
    "ESTIMATORS = {\n",
    "    \"K-nn\": KNeighborsRegressor(),\n",
    "    \"Linear regression\": LinearRegression()\n",
    "}\n",
    "\n",
    "# Imprimindo as faces\n",
    "image_shape = (64, 64)\n",
    "\n",
    "# O número de colunas é a quantidade de algoritmos (cada imagem gerada por um) e a imagem original\n",
    "n_cols = 1 + len(ESTIMATORS)\n",
    "plt.figure(figsize=(2. * n_cols, 2.26 * n_faces))\n",
    "plt.suptitle(\"Completando faces com estimadores\", size=16)\n",
    "\n",
    "for i in range(n_faces):\n",
    "    true_face = np.hstack((X_test[i], y_test[i]))    # Seleciona a imagem original\n",
    "\n",
    "    if i:    # Posição da imagem\n",
    "        sub = plt.subplot(n_faces, n_cols, i * n_cols + 1)\n",
    "    else:\n",
    "        sub = plt.subplot(n_faces, n_cols, i * n_cols + 1,\n",
    "                          title=\"true faces\")\n",
    "\n",
    "    sub.axis(\"off\")\n",
    "    sub.imshow(true_face.reshape(image_shape),\n",
    "               cmap=plt.cm.gray,\n",
    "               interpolation=\"nearest\")    # Diminui a resolução, torna a imagem preto e branco\n",
    "\n",
    "    for j, est in enumerate(sorted(ESTIMATORS)):    # Para cada um dos algoritmos\n",
    "        completed_face = np.hstack((X_test[i], y_test_predict[est][i]))    # Pega a imagem estimada pelo algoritmo\n",
    "\n",
    "        if i:\n",
    "            sub = plt.subplot(n_faces, n_cols, i * n_cols + 2 + j)\n",
    "        else:\n",
    "            sub = plt.subplot(n_faces, n_cols, i * n_cols + 2 + j,\n",
    "                              title=est)\n",
    "\n",
    "        sub.axis(\"off\")\n",
    "        sub.imshow(completed_face.reshape(image_shape),\n",
    "                   cmap=plt.cm.gray,\n",
    "                   interpolation=\"nearest\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Árvore de Decisão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mais informações em\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voltamos a usar a base de dados de plantas Íris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parâmetros\n",
    "n_classes = 3\n",
    "plot_colors = \"bry\"\n",
    "plot_step = 0.02\n",
    "\n",
    "# Mesma base de dados do algoritmo anterior\n",
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(num = None, figsize = (6, 7), dpi = 80)\n",
    "\n",
    "for pairidx, pair in enumerate([[0, 1], [0, 2], [0, 3],\n",
    "                                [1, 2], [1, 3], [2, 3]]):\n",
    "    \n",
    "    # Usa apenas dois parâmetros para representar cada objeto\n",
    "    X = iris.data[:, pair]\n",
    "    y = iris.target\n",
    "    \n",
    "    ##############################################################################\n",
    "    # Treinamento\n",
    "    ##############################################################################\n",
    "    clf = DecisionTreeClassifier().fit(X, y)\n",
    "\n",
    "    # Mostra os limites (onde passa de uma classe para outra)\n",
    "    plt.subplot(3, 2, pairidx + 1)\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                         np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "    ##############################################################################\n",
    "    # Testes\n",
    "    ##############################################################################\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.summer)\n",
    "\n",
    "    plt.xlabel(iris.feature_names[pair[0]])\n",
    "    plt.ylabel(iris.feature_names[pair[1]])\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Mostrando os pontos usandos para o treino\n",
    "    for i, color in zip(range(n_classes), plot_colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                    cmap=plt.cm.Paired)\n",
    "\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para gerar a árvore de decisão utilizada no exemplo atual\n",
    "# Precisa instalar antes: sudo apt-get install graphviz\n",
    "from sklearn import tree              # É um módulo que possui as árvores de decisão para regressão e classificação\n",
    "!pip install pydotplus                # Python Interface com Graphviz\n",
    "import pydotplus                      # http://www.graphviz.org/\n",
    "\n",
    "dot_data = tree.export_graphviz(clf, out_file=None, \n",
    "                         feature_names=iris.feature_names,  \n",
    "                         class_names=iris.target_names,  \n",
    "                         filled=True, rounded=True,  \n",
    "                         special_characters=True)   \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "graph.write_pdf(\"iris.pdf\")          # Salva a árvore no pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício 3 (Árvore de Decisão)\n",
    "\n",
    "Usando o seguinte banco de dados usar o algortimo de árvore de decisão para descobrir classes de animes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando os dados\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "animes = pd.read_csv(\"animes.csv\", \";\")\n",
    "animes.head()\n",
    "\n",
    "# genres: mecha, music, historical\n",
    "\n",
    "# Vamos definir 3 classes: \n",
    "# -> 0: animes bons\n",
    "# -> 1: animes médianos\n",
    "# -> 2: animes ruins \n",
    "\n",
    "class_ = []\n",
    "for id_, row in animes.iterrows():\n",
    "    if random.randint(0, 10) < 8:\n",
    "        rating = row['rating']\n",
    "        if rating > 7:\n",
    "            class_.append(0)\n",
    "        elif rating <= 7 and rating > 5:\n",
    "            class_.append(1)\n",
    "        else:\n",
    "            class_.append(2)\n",
    "    else: # Vamos adicionar algum ruído\n",
    "        class_.append(random.randint(0, 2))\n",
    "animes[\"class\"] = class_\n",
    "animes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_features = animes.drop([\"id\", \"name\", \"class\", \"source\", \"type\"], axis = 1)\n",
    "animes_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animes_target = animes[\"class\"]\n",
    "animes_target.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM\n",
    "\n",
    "Breves comentários: o SVM funciona como um classificador binário, dada uma base de dados ele tenta dividir essa base usando um hiperplano. Para utilizar com mais de uma classe, basta pensar o seguinte, temos 4 classes, cada classe é um bit, dessa forma, temos que 0001, 0010, 0100 e 1000, onde o primeiro bit (menos significativo representa a classe 0, e assim por diante)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dúvidas? \n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "# Importando o que é necessário (similar ao que já foi feito antes)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "\n",
    "# Mesma base de dados conhecida\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2] # Vamos simplificar nossos dados\n",
    "y = iris.target\n",
    "\n",
    "h = .02 \n",
    "C = 1.0  # parâmetro para SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Agora o classificador \n",
    "clf = svm.LinearSVC(C = C).fit(X, y)\n",
    "\n",
    "# Criamos uma malha de pontos para plotar (similar a outros exemplos)\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Resultados da malha\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.5)\n",
    "\n",
    "# Agora os pontos usados para treinar\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, marker = '.')\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "plt.title('LinearSVC (linear kernel)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exercício 4\n",
    "\n",
    "Use a mesma base com animes para fazer classificação dos animes, agora usando o SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solução"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
